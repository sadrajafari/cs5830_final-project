{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Forecasting of Solar Flares using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, Dense\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickledFile(fileName):\n",
    "    bytes_in = bytearray(0)\n",
    "    max_bytes = 2**31 - 1\n",
    "    input_size = os.path.getsize(fileName)\n",
    "    with open(fileName, 'rb') as file:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            bytes_in += file.read(max_bytes)\n",
    "        obj = pickle.loads(bytes_in)\n",
    "        file.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "As shown in analysisAndVisualization, there are 6 magnetic field parameters which are highly correlated with flare type. These 6 are the features we will use for the LSTM. The LSTM model will take in 24 hours of past magnetic field data, and predict what the most severe solar flare in the next hour will be. The data contains a major class imbalance, so we created a new dataset with more balanced classes in order to prevent overfitting. We will train on the balanced data, then test on the real data. The code for creation of this balanced dataset can be found in `create_balanced_datasets.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loadPickledFile(\"balanced_data/X_train.pck\")\n",
    "X_test = loadPickledFile(\"balanced_data/X_test.pck\")\n",
    "y_train = loadPickledFile(\"balanced_data/y_train.pck\")\n",
    "y_test = loadPickledFile(\"balanced_data/y_test.pck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Net\n",
    "\n",
    "Recurrent Neural Networks such as the LSTM are well-suited for timeseries forecasting, so our model will just be a simple LSTM. This is a multi-class classification problem, so categorical cross entropy is the most suitable loss function, and the softmax function is the most suitable activation function for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train[0].shape[1]\n",
    "num_classes = 5\n",
    "model = Sequential()\n",
    "# Input Layer\n",
    "model.add(Dense(num_features, input_shape=X_train[0].shape,activation='relu'))\n",
    "# Hidden Layers: RNN\n",
    "model.add(LSTM(units=20*num_features)) # Add return_sequences=True if you want to add more architecture\n",
    "# model.add(GRU(units=2*num_features, return_sequences=True))\n",
    "# model.add(SimpleRNN(units=2*num_features))\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will reserve 20% of the training data for validation, and train the network. If the validation loss stops improving, we will stop training so the model does not overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "val_split = 0.2\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_split=val_split,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting Model\n",
    "\n",
    "Next, we persist the model so it can be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"lstm-balanced\"\n",
    "model.save(f\"persisted_nets/{modelName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Evaluating Model\n",
    "\n",
    "Now, we can load the model back in from the file, and evaluate it. First, we will evaluate it on the balanced dataset. Then, we can evaluate it on real timeseries data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"lstm-balanced\"\n",
    "model = load_model(f\"persisted_nets/{modelName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabels = {\n",
    "    0: \"0\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"M\",\n",
    "    4: \"X\"\n",
    "}\n",
    "\n",
    "def threshold_output(output):\n",
    "    thresholded = []\n",
    "    for arr in output:\n",
    "        thresholded.append(np.array([np.array([np.argmax(arr)])]))\n",
    "    return np.array(thresholded)\n",
    "    \n",
    "def printMetrics(p,r,f,s):\n",
    "    for i in range(len(p)):\n",
    "        print(f\"Metrics for {classLabels[i]} class flares\")\n",
    "        print(f\"\\tPrecision: {p[i]}\")\n",
    "        print(f\"\\tRecall:    {r[i]}\")\n",
    "        print(f\"\\tF-Score:   {f[i]}\")\n",
    "        print(f\"\\tSupport:   {s[i]}\")\n",
    "\n",
    "def evaluate_model(model,X_test,y_test, plotTitle):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = threshold_output(y_pred)\n",
    "\n",
    "    p,r,f,s = precision_recall_fscore_support(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "    printMetrics(p,r,f,s)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_test.flatten(), y_pred.flatten(), display_labels=[\"No Flare\",\"B\", \"C\", \"M\", \"X\"])\n",
    "    disp.ax_.set_title(plotTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_test, y_test, \"Confusion Matrix for Balanced Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the metrics and confusion matrix above, the model has a difficult time predicting X-class flares. This is likely because the number of X-class flares is small. In the future, we can improve the prediction of X-class flares by using a more deep, sophisticated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Model on Unbalanced Data\n",
    "\n",
    "Real solar flare data is **very** unbalanced, so we need to see how our model performs on the real, unbalanced data. The data used for this evaluation is just data from the year 2014, transformed into a format which the LSTM can take. Creation of this dataset is done in `create_LSTM_datasets.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loadPickledFile(\"timeseries/X_train.pck\")\n",
    "X_test = loadPickledFile(\"timeseries/X_test.pck\")\n",
    "y_train = loadPickledFile(\"timeseries/y_train.pck\")\n",
    "y_test = loadPickledFile(\"timeseries/y_test.pck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_test, y_test, \"Confusion Matrix for unbalanced 2014 time series data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the confusion matrix and metrics above, our model has difficulties discerning between the \"No Flare\" case and B- and C- class flares. Because of the severity of M and X class flares, they are more important to predict than the less severe solar flares, and we see that the recall of M-class flares is around 40%, which for a simple model is not bad for timeseries prediction. The X-class prediction, however, is not at all good, with no flares being correctly predicted. Once again, a more sophisticated, deep machine learning model would help to make this better. With solar flares, predicting the \"No Flare\" condition is not as important as predicting a solar flare, so the metrics we care most about are the **recall** for each of the solar flare classes. The recall of the B- and C- class flares are around 60%, which is acceptable. The M- and X- class recall are not as favorable, as mentioned above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
